{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA) \n",
    "\n",
    "~~~\n",
    "Extracción de Características en Imágenes.\n",
    "Master en Ciencia de Datos e Ingeniería de Computadores.\n",
    "Universidad de Granada.\n",
    "\n",
    "Fernando Pérez Bueno - fpb@ugr.es\n",
    "Francisco Miguel Castro Macías - fcastro@ugr.es\n",
    "Rafael Molina Soriano - rms@decsai.ugr.es\n",
    "~~~\n",
    "\n",
    "Vamos a utilizar el análisis de componentes principales (Principal Component Analysis, PCA) sobre una base de datos de caras para reducir la dimensionalidad de cada cara extrayendo un conjunto de variables latentes. Estas variables latentes podrían, con posterioridad, utilizarse, por ejemplo, en problemas de clasificación siempre que los errores de reconstrucción de las caras usando las variables latentes fuese pequeño. También podrían usarse en problemas de detección de anomalías.\n",
    "\n",
    "El fichero ERRDfaces.mat contiene una base de datos de caras almacenada por filas en la matriz `X`. Cada fila corresponde a una cara de 32x32=1024 píxeles en niveles de gris. El número de ejemplos es 5000.\n",
    "\n",
    "Comenzamos importando las librerías que vamos a utilizar en el desarrollo de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especificamos la ruta donde están nuestros datos y los leemos. Observa la estructura que los contiene. Lee la documentación sobre la función `loadmat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "path='C://Users/cacoq/Dropbox/Trabajo/Docencia/DATCOM_ECI_22-23/'\n",
    "\n",
    "dict_data = loadmat(path+'ERRDfaces_2021.mat')\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ves, los datos están almacenados en un diccionario. Extraemos nuestros datos usando la llave `X` y mostramos su dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= dict_data['X']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos las 4.500 primeras caras como ejemplos de entrenamiento y las restantes 500 como test. El conjunto de test nos servirá para probar que PCA representa suficientemente bien la información como para aplicarlo a datos que no ha visto.\n",
    "\n",
    "Dependiendo del problema podríamos usar todas las muestras como conjunto de entrenamiento. Por ejemplo, si quisiéramos detectar anomalías en el conjunto de imagenes, debemos usar un conjunto \"de calibración\".\n",
    "\n",
    "> 📝 **Pregunta 1.** Completa el código para que la variable `X` siguiente contenga las 4500 primeras caras de `data` y `test` el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_tr = 4500\n",
    "X = \n",
    "test ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las caras están almacenadas como un vector de rasgos, donde cada imagen es una única fila. \n",
    "\n",
    "> 📝 **Pregunta 2.** Redimensiona, es decir, pasa de un vector con 1024 componentes a una matriz 32x32, y muestra las 5 primeras caras del dataset. Pueden resultarte utiles las funciones `np.reshape` y `plt.imshow`. Tal vez necesites trasponer la matriz que contiene la cara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_caras = 5\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "#Introduce aquí tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización de los datos \n",
    "\n",
    "Para trabajar con modelos como PCA, es necesario normalizar los datos. Recuerda una de las primeras cosas que comentó Rafa:\n",
    "\\begin{equation*}\n",
    "\\mathbf{x} \\approx \\mathbf{\\phi} \\mathbf{z} \\color{red}{+ \\boldsymbol{\\mu}}\n",
    "\\end{equation*}\n",
    "\"Nosotros supondremos que $\\color{red}{\\boldsymbol{\\mu}=\\boldsymbol{0}}$\"\n",
    "\n",
    "> 📝 **Pregunta 3.** Usando la clase `StandardScaler` de sklearn normaliza los datos de entrenamiento, de forma que cada rasgo (de los 1024) tenga media cero. No realices el escalado de la varianza a uno. Los rasgos normalizados deberás almacenarlos en la variable `X_norm`. Ten en cuenta que más tarde tendrás que aplicar la misma normalización a los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Introduce aquí tu código para normalizar los datos. Introduce los datos normalizados en una variable de nombre X_norm\n",
    "\n",
    "X_norm ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 4.** Escribe código, lo más eficiente posible, para comprobar que las columnas de rasgos tienen media cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de las PCAs \n",
    "\n",
    "Una vez que has normalizado los datos. Utilizaremos `X_norm` para calcular las componentes principales. Aunque existe una función implementada en el paquete sklearn nosotros no la utilizaremos para comprender en profundidad el funcionamiento de PCAs. No se considera válido para el desarrollo de la práctica el uso de implementaciones de PCA en sklearn o cualquier otra libreria.\n",
    "\n",
    "Supongamos que $\\mathbf{X} \\in \\mathbb{R}^{N \\times D}$ y que queremos proyectar nuestros datos en un espacio de dimensión $M$. Recuerda que el cálculo de las componentes principales viene dado por la solución al problema\n",
    "$$ \\min_{\\mathbf{W} \\in \\mathbb{R}^{D \\times M}, \\mathbf{Z} \\in \\mathbb{R}^{N \\times M}} \\| \\mathbf{X}^\\top - \\mathbf{W}\\mathbf{Z}^\\top\\|_F^2.$$\n",
    "En teoría hemos visto que tal solución viene dada tomando\n",
    "$$ \\mathbf{W} = \\mathrm{Eigenvec}(\\mathbf{S})_M, \\quad \\mathbf{Z}^\\top = \\mathbf{W}^\\top \\mathbf{X}^\\top$$\n",
    "donde $\\mathrm{Eigenvec}(\\mathbf{S})_M$ contiene los $M$ autovectores (vectores propios) con mayores autovalores (valores propios) de la matriz de covarianza muestral $\\mathbf{S} = (1/N) \\mathbf{X}^\\top \\mathbf{X}$. La reconstrucción se realiza tomando \n",
    "$$ \\hat{\\mathbf{X}}^\\top =  \\mathbf{W} \\mathbf{Z}^\\top.$$\n",
    "\n",
    "Para calcular las componentes principales necesitamos calcular los autovectores de $\\mathbf{X}^\\top \\mathbf{X}$. En teoría hemos visto que se pueden calcular a partir de la descomposición en valores singurales $\\mathbf{X}^\\top = \\mathbf{V} \\mathbf{D} \\mathbf{U}^\\top$. Tenemos que \n",
    "$$ \\mathbf{S} = \\frac{1}{N} \\mathbf{V} \\mathbf{D}^2 \\mathbf{V}^\\top,$$\n",
    "lo que significa que los autovectores de $\\mathbf{S}$ se encuentran en las columnas de $\\mathbf{V}$ y los autovalores vienen dados por $\\lambda_i = (1/N) \\mathbf{D}_{ii}^2$. Recuerda que $\\mathbf{D}$ es una matriz diagonal.\n",
    "\n",
    "> 📝 **Pregunta 5.** Utiliza la descomposición por valores sigulares sobre `X_norm` o `X_norm` traspuesta usando la función `np.linalg.svd()`. Obtén los autovectores y con los valores singulares calcula los autovalores. Alternativamente, puedes calcular los autovectores y autovalores de la matriz de covarianza muestral de `X_norm` utilizando la función `np.linalg.eig()`. Tal vez sería bueno que lo hicieras con los dos métodos y comprobases que obtienes los mismos autovalores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce aqui tu codigo para calcular los autovalores y los autovectores\n",
    "\n",
    "# Introduce en autovalores los autovalores (ordenados) de la matriz de covarianza muestral\n",
    "autovalores=\n",
    "\n",
    "# Introduce en autovectores los vectores (ordenados) que definen la transformación de PCA\n",
    "autovectores ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Número de componentes a utilizar\n",
    "\n",
    "Vamos ahora a determinar cuantas componentes vamos a utilizar en nuestro analisis. Cada componente adicional explica parte de la varianza de nuestros datos. Queremos encontrar cuántas componentes son necesarias para representar bien nuestros datos. \n",
    "\n",
    "Usando los autovalores que hemos obtenido, podemos observar qué cantidad de información aporta cada una de las componentes. Las dos gráficas a continuación muestran esta información de dos formas diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Hacemos uso de la suma acumulada de los autovalores para ver la varianza acumulada\n",
    "cumsum=np.cumsum(autovalores)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(cumsum/cumsum[-1])\n",
    "plt.title('Varianza acumulada')\n",
    "plt.subplot(2,1,2)\n",
    "#El aporte de cada autovalor a la suma total, nos muestra la varianza explicada por cada componente\n",
    "plt.bar(range(autovalores.shape[0]),autovalores/np.sum(autovalores))\n",
    "plt.title('Varianza explicada por cada componente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque podemos fijar el número de componentes manualmente tras estudiar los datos, es bueno que pienses como determinarías automáticamente el número de componentes a utilizar.\n",
    "\n",
    "> 📝 **Pregunta 6.** ¿Qué harías para determinar cuál sería un buen número de componentes? Justifica tu respuesta. No es necesario que lo implementes.\n",
    "\n",
    "Responde aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización de las autocaras\n",
    "\n",
    "En el caso de las caras, se puede apreciar muy bien la información que captura cada una de las componentes principales visualizando las llamadas autocaras que no son más que los autovectores. Cada uno de los autovectores que hemos calculado representa elementos clave de una cara que pueden utilizarse para componer la imagen final.\n",
    "\n",
    "> 📝 **Pregunta 7.** Igual que hiciste con las imágenes, escribe aquí código que permita visualizar los primeros 5 autovectores en forma de imagen. Es decir, los 5 autovectores asociados a los 5 autovalores mayores. Tendrás que redimensionar los vectores para darles formato de imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce aquí tu código para representar las 5 primeras autocaras\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 8.** Escribe aquí el código que permita visulizar los cinco últimos 5 autovectores en forma de imagen. Es decir, los 5 autovectores asociados a los 5 menores autovalores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce aquí tu código para representar las 5 últimas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 9.** ¿Por qué son tan diferentes? \n",
    "\n",
    "Responde aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de las componentes principales de los datos\n",
    "\n",
    "Hasta ahora hemos obtenido los vectores (autovectores o autocaras) que definen el subespacio donde vamos a proyectar los datos. También hemos visto qué cantidad de varianza explica cada autovector. \n",
    "\n",
    "Vamos a fijar el número de autocaras a 250, es decir `n_componentes=250`.\n",
    "\n",
    "> 📝 **Pregunta 10.** Extrae de `V` los `n_componentes` autovectores asociados a los `n_componentes` mayores autovalores y almacénalos en `W`. A continuación obtén la proyección (variables latentes) de nuestros datos y almacénalos en `Z`. Observa que lo que estamos haciendo es proyectar nuestros datos originales `X_norm` en el espacio generado por los vectores de `W`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_componentes = 250\n",
    "\n",
    "# W contendrá los autovectores correspondientes a las n_componentes principales\n",
    "\n",
    "W =\n",
    "\n",
    "# Z contendrá las proyecciones de nuestros datos en el espacio latente\n",
    "\n",
    "Z =\n",
    "\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización de las primeras componentes\n",
    "\n",
    "Podemos visualizar la primera y la segunda componentes para ver que información nos aportan sobre nuestros datos. \n",
    "\n",
    "> 📝 **Pregunta 11.** Crea dos gráficas separadas. Una que muestre solo la primera componente (variable latente) y otra que incluya las dos primeras (variables latentes) de todo el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluye aquí el código de la creación de las gráficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 12.** Comenta los resultados obtenidos.\n",
    "\n",
    "Responde aquí. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperacion de los datos\n",
    "\n",
    "A partir de las variables latentes almacenadas en `Z`, cada una de sus filas contiene la representación latente de cada uno de los ejemplos (filas) en `X_norm`, podemos reconstruir los datos. Observa que hemos pasado de 1024 rasgos a `n_componentes`. \n",
    "\n",
    "> 📝 **Pregunta 13.** Utiliza `Z` y los autovectores en `W` para reconstruir las caras originales. Ten en cuenta que tendrás que deshacer la normalización de los datos una vez hayas recuperado la dimensionalidad original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce aquí tu código para recuperar los datos\n",
    "X_norm_recovered =\n",
    "X_recovered = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 14.** Muestra las 5 primeras caras de la base de datos original y su reconstrucción. Si has hecho los pasos correctamente, la reconstrucción debe ser similar al original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra 5 caras del dataset original y las mismas 5 caras reconstruidas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 15.** ¿Qué ocurre si aumentamos o disminuímos el número `n_componentes`?\n",
    "\n",
    "Reponde aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medición del error de reconstrucción\n",
    "\n",
    "Según el número de componentes que hayamos utilizado, habremos perdido más o menos información. Podemos comprobarlo haciendo uso del error cuadratico medio (MSE). \n",
    "\n",
    "> 📝 **Pregunta 16.** Usando los datos originales de entrenamiento `X` y la reconstrucción que has obtenido, calcula el MSE que has cometido con cada una de las imágenes en `X`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce aquí tu código para calcular el MSE. Si lo has hecho bien, obtendrás un valor para cada elemento (fila) \n",
    "# de X.\n",
    "\n",
    "mse=\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 17.** Haciendo uso del error cuadrático medio identifica y muestra la imagen original y la reconstruida en los siguientes casos: la imagen peor reconstruida, la imagen mejor reconstruida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluye el código para encontrar en el conjunto de entregamiento las imágenes peor y mejor reconstruidas usando el\n",
    "# error cuadrático medio y muéstrales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 18.** ¿Podrías explicar por qué son estas las caras que aparecen?\n",
    "\n",
    "Responde aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando el modelo a datos nuevos \n",
    "\n",
    "Los autovectores o autocaras que hemos encontrado haciendo uso de `X` deberian ser suficientemente buenos para representar otros datos del mismo tipo. Vamos a comprobarlo haciendo uso del pequeño conjunto de test que separamos al principio de la práctica.\n",
    "\n",
    "Utilizando los autovectores que ya has calculado, sigue los mismos pasos con las imagenes de test y comprueba que el funcionamiento es adecuado. \n",
    "\n",
    "> 📝 **Pregunta 19.** Normaliza las instancias de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos de test. (No olvides que no puedes utilizar información obtenida del propio \n",
    "# conjunto de test)\n",
    "\n",
    "test_norm ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 20.** Obtén las variables latentes y reconstruye las caras del conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenición de las variables latentes y reconstrucción de las caras de test.\n",
    "\n",
    "Z_test=\n",
    "\n",
    "Test_norm_recovered =\n",
    "\n",
    "Test_recovered =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 21.** Muestra las cinco primeras caras del conjunto de test y sus reconstrucciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra 5 caras del conjunto de test y sus respectivas reconstrucciones\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de anomalías\n",
    "\n",
    "En el conjunto de test hay una imagen anómala que no se corresponde con el resto del dataset. ¿Como la identificarías automaticamente utilizando lo que has aprendido?\n",
    "\n",
    "> 📝 **Pregunta 22.** Identifica y muestra la anomalía oculta en el conjunto de test. Muestra también la reconstrucción que hemos obtenido de esa anomalía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica la anomalía en el conjunto de test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 **Pregunta 23.** ¿Qué es lo que nos permite identificar la imagen como anomalía? ¿Por qué se reconstruye de esa manera?\n",
    "\n",
    "Responde aquí. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "243a74b9a28e90d0280f4a150ec4bf03d37a0e42fbedcb7e7556bf3d8cfb8e05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
